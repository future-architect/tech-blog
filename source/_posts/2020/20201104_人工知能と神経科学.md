---
title: "人工知能と神経科学"
date: 2020/11/04 00:00:00
postid: ""
tag:
  - DeepLearning
  - 強化学習
category:
  - DataScience
thumbnail: /images/20201104/thumbnail.png
author: 戸田聖人
lede: "他の秋のブログ週間連載と結構毛色が違うため、本記事を見て合わないと思った場合には他の記事でお口直しをお願いします…。秋の夜長に合う読み物、ということだったので、最近では身近になった「人工知能」とその隣人である「神経科学」について書こうと思います。"
---

<img src="/images/20201104/brain-2029391_1280.png" class="img-middle-size" alt="" title="OpenClipart-VectorsによるPixabayからの画像">

2020年4月新卒入社、フューチャーアーキテクトの戸田です。

この記事は[秋のブログ週間連載](/articles/20201026/)の第5弾です。他の秋のブログ週間連載と毛色が多少異なりますが、楽しんで貰えると幸いです。

秋の夜長に合う読み物、ということだったので、最近では身近になった「人工知能」とその隣人である「神経科学」について書こうと思います。私事ですが、筆者の学生時代の専門が「神経科学」であり、情報系ではなく生物系出身や色々な人がフューチャーに在籍しているよ、と伝えたく筆を取りました。

## 1. 神経科学（Neuroscience）とは

名前の通り、生き物の体に張り巡らされる「神経（Neuro）」について研究を行う自然「科学（Sciense）」の一分野です。非常に簡単に言うと、生き物が感じ・考え・動くことを調べる分野のことを指します。

```
どのようにして私たちはものを見たり，聞いたりするのだろうか。
快く感じることもあれば苦痛に感じることもあるのはなぜだろうか。
どのようにして私たちは体を動かすのだろうか。
また， どのようにして私たちは推論し，学習し記憶し，そして忘れるのだろうか。
怒りや狂気の本質は何だろうか。 このようなことに興味を抱くのは人間として自然である。
これらの謎を基礎的な神経科学の見地から解明する研究が始まっている。
そして，これらの研究の成果が本書の主題である。
```
（M.F.ベアー. ベアー・コノーズ・パラディーソ 神経科学：脳の探求 カラー版 より [^1]）

しかし、そんな生き物に関わる研究が、どのようにして情報系の分野である「人工知能」に影響を及ぼしたのか、同時に影響を及ぼされたのかを簡単にですが説明していこうと思います。

## 2.「人工知能」と「神経科学」の歴史

AIという言葉が使われ、その歴史が始まったのは1956年のダートマス会議 [^2]のことですが、そこからすべての「人工知能（Artificial intelligence; AI）」の歴史についてここに記す事はできないため、「神経科学」とそれに関わりの深い「深層学習」に絞って話をしていきます。

### 2.0. 「深層学習」が脚光を浴びてから

ご存じの方も多いでしょうが、「深層学習」は2012年のNIPS会議においてヒントンら [^3]が画像解析での圧倒的な性能を示して以来、画像認識を始めとして、言語処理、音声認識など様々な分野において活躍を残しています [^4]。

その「深層学習」において用いられる、「ニューラルネットワーク（Neural Network; NN）」は、日本語に無理やり直せば「神経回路網」となります。名前の通り、現在活躍する人工知能に関する手法の起源は神経科学にあります [^5]。

それでは、「深層学習」と「神経科学」の歴史を辿っていきましょう。

### 2.1. 「形式ニューロン」と「全か無かの法則」

一番初めのNNモデルは1943年に、ピッツとマッカロック [^6]が発表した「形式ニューロン」と呼ばれるものです。これは、神経科学において発見された「全か無かの法則」を数理的に表現したものでした。

「全か無かの法則」は、神経細胞（Neuron）の活動に関する法則で、神経細胞に一定上の入力がある場合には活動し、一定以下の入力には活動しないという法則です。つまり、「形式ニューロン」も入力値が一定を超えた場合に"1"を、超えなかった場合に"0"を出します(出力する値は定義次第ですが、今回はTrueとFalseを意識して1,0としました)。この「形式ニューロン」でどんな事ができるかというと、例えば、論理演算のANDを表現することが可能です。

### 2.2.教師なし学習としての「ヘッブ則」

1949年にはヘッブが神経細胞間の関係について仮設を唱えました [^7]。俗に「ヘッブ則」と呼ばれる法則です。「ヘッブ則」は、神経科学にも大きな影響を与えましたが、人工知能の分野にも大きな影響を与えました。

ヘッブは、その法則を以下のように表現しています。

```
「細胞Aの軸索が細胞Bを発火させるのに十分近くにあり、
繰り返しあるいは絶え間なくその発火に参加するとき、
いくつかの成長過程あるいは代謝変化が一方あるいは両方の細胞に起こり、
細胞Bを発火させる細胞の1つとして細胞Aの効率が増加する。」
```
（高橋 直矢, 池谷裕二, 松木則夫. ヘブ則. 脳科学辞典 より [^8])

ここで、`発火`は神経細胞、すなわちニューロンの活動のことを指し、`細胞Aの軸索が細胞Bを発火させるのに十分近くにあり`というのは細胞Aと細胞Bとの活動に関連があること、すなわち、ニューロン間に入力の関係があることを指します。

要約すれば、`ニューロンAの活動がニューロンBの活動を引き起こすと、ニューロンAの活動がニューロンBを活動させやすくなる`となります。これはつまり、教師となる外部の信号なしに、ニューロン同士の関係を変化させる、教師なし学習に関する最初のアイデア [^4]でした。

### 2.3. 「形式ニューロン」をつなげた「パーセプトロン」

1958年にはローゼンブラッドがNNモデルである「パーセプトロン」を発表しました [^9]。節名の通り、「パーセプトロン」は「形式ニューロン」を複数つなげたものであり、一つの「形式ニューロン」で論理演算が可能であるのならば、複数個「形式ニューロン」をつなげればより複雑な入出力の関係を表現できるだろう、というアイデアでした。このときローゼンブラッドがパーセプトロンの学習則として使った方法が、前に説明したヘッブ則でした。

本筋とは関係ありませんが、この「パーセプトロン」では線形分離が出来ない問題が解けないということで下火になっていきました [^10]。

実はさらに「形式ニューロン」をつなげる、つまり、層を増やせば線形分離が出来ない問題も解くことができることはわかっていましたが、ヘッブ則では層を増やした「パーセプトロン」を学習させることが出来ないことが問題でした。


### 2.4.バックプロパゲーションの開発とその後の深層学習

1986年に、前節で話した多層のパーセプトロンを学習させられない、という問題を解決できる「バックプロパゲーション」をランメルハルトらが発表しました [^11]。彼らは、並列分散処理モデルの研究していた神経科学と認知科学者のグループでした [^12]。さらに、その後ランメルハルトとともに「バックプロパゲーション」を発表した、ヒントンが研究を続け、2012年のNIPS会議へとつながっていきます。

並列分散処理モデルは、コネクショニズムとも呼ばれ、神経細胞群を抽象化された処理の単位（ユニット）とし、それのネットワークを用いて認知メカニズムを理解しようとするアプローチであり、現在のNNモデルと共通点も多くあります [^13]。

並列分散処理モデルと神経科学は、人工知能の研究に色々なアイデアを提供しました [^5]。現在の機械翻訳における、単語や文を分解して（ベクトルとして）表現できるという概念 [^14]や、視覚情報を処理する脳領域に関する実験 [^15]から発想を得た、畳み込みニューラルネットワークに見られる非線形変換・分割正規化・最大プーリング [^16]などが例として挙げられます。

また、トレーニングデータに過剰に適合してしまう、過学習を防ぐために行われる正則化であるドロップアウトの開発も、ポワソン分布で活動する神経細胞の存在に動機づけられました [^5], [^17]。さらに、強化学習も動物心理学における動物実験の研究に触発されています [^18]。

一方で、強化学習の手法であるTD学習（Temporal difference learning）から得られた結果と生物の脳から計測された神経の活動はよく似ており、生物の脳がTD学習と類似した方法を用いていることが示唆されています [^19], [^20]。

深層学習による、神経科学への影響はアルゴリズムに限りません。近年では、神経科学において処理するデータ量が飛躍的に増加しており解析手法として深層学習が用いられることも多いです。

## まとめ

* 「神経科学」とは、脳などの神経について研究を行う分野のことである。
* 「人工知能」と関係する「神経科学」という分野がある。
* 歴史的に「人工知能」と「神経科学」は影響を与えあってきた。

過去から現在まで、簡単かつ駆け足ではありますが「人工知能」と「神経科学」の関係を書きました。

込み入った話を含めれば、さらに色々書くことはありますが、「神経科学」の知識がないと理解が難しいため比較的理解しやすいものを書いてみました。また機会があれば、現在の話やこれからの話についても書けたらいいなと考えています。

本記事は、ハサビスらの論文 [^5]とシュミットフーバーの論文 [^4]を中軸として書いたので気になる方は、原著も読んでみてください。


 [^1]: 加藤宏司, et al. "ベアー コノーズ パラディーソ神経科学: 脳の探求: カラー版." (2007).

 [^2]: McCarthy, John, et al. "A proposal for the dartmouth summer research project on artificial intelligence, august 31, 1955." AI magazine 27.4 (2006): 12-12.

 [^3]: Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "ImageNet classification with deep convolutional neural networks." NIPS'12: Proceedings of the 25th International Conference on Neural Information Processing Systems(2012): 1097–1105.

 [^4]: Schmidhuber, Jürgen. "Deep learning in neural networks: An overview." Neural networks 61 (2015): 85-117.

 [^5]: Hassabis, Demis, et al. "Neuroscience-inspired artificial intelligence." Neuron 95.2 (2017): 245-258.

 [^6]: McCulloch, Warren S., and Walter Pitts. "A logical calculus of the ideas immanent in nervous activity." The bulletin of mathematical biophysics 5.4 (1943): 115-133.

 [^7]: Hebb, Donald Olding. "The organization of behavior: a neuropsychological theory." J. Wiley; Chapman & Hall, 1949.

 [^8]: 高橋 直矢, 池谷裕二, 松木則夫. "ヘブ則". 脳科学辞典(2012), アクセス日 2020/11/04, https://bsd.neuroinf.jp/wiki/%E3%83%98%E3%83%96%E5%89%87

 [^9]: Rosenblatt, Frank. "The perceptron: a probabilistic model for information storage and organization in the brain." Psychological review 65.6 (1958): 386.

 [^10]: Minsky, Marvin L., and Seymour A. Papert. "Perceptrons: expanded edition." (1988).

[^11]: Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. "Learning representations by back-propagating errors." nature 323.6088 (1986): 533-536.

 [^12]: Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. Learning internal representations by error propagation. No. ICS-8506. California Univ San Diego La Jolla Inst for Cognitive Science, 1985.

 [^13]: 都築誉史. "コネクショニズム." 認知科学 8.3 (2001): 225-237.

 [^14]: John, Mark F. St, and James L. McClelland. "Learning and applying contextual constraints in sentence comprehension." Artificial intelligence 46.1-2 (1990): 217-257.

 [^15]: Hubel, David H., and Torsten N. Wiesel. "Receptive fields of single neurones in the cat's striate cortex." The Journal of physiology 148.3 (1959): 574.

 [^16]: Yamins, Daniel LK, and James J. DiCarlo. "Using goal-driven deep learning models to understand sensory cortex." Nature neuroscience 19.3 (2016): 356-365.

 [^17]: Hinton, Geoffrey E., et al. "Improving neural networks by preventing co-adaptation of feature detectors." arXiv preprint arXiv:1207.0580 (2012).

 [^18]: Sutton, Richard S., and Andrew G. Barto. Reinforcement learning: An introduction. MIT press, 2018.

 [^19]: O'Doherty, John P., et al. "Temporal difference models and reward-related learning in the human brain." Neuron 38.2 (2003): 329-337.

 [^20]: Schultz, Wolfram, Peter Dayan, and P. Read Montague. "A neural substrate of prediction and reward." Science 275.5306 (1997): 1593-1599.

