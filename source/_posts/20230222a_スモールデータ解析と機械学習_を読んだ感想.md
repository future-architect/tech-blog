---
title: "スモールデータ解析と機械学習 を読んだ感想"
date: 2023/02/22 00:00:00
postid: a
tag:
  - 書籍
  - 書評
  - 機械学習
category:
  - DataScience
thumbnail: /images/20230222a/thumbnail.jpg
author: 大村俊輔
lede: "Kaggle、AtCoder等の趣味が高じて2022年12月フューチャーに入社しました。このような背景の人がフューチャーに入社後、何が不足していると感じ、どのようにそれを埋めていこうとしているのか。といった目線でお読みいただければ幸いです。"
---

積読を消化しようというテーマの、[読書感想文連載](/articles/20230217a/) の3冊目です。

# はじめに

2022年12月キャリア入社の大村俊輔です。

[Kaggle](https://www.kaggle.com/)(競技データサイエンス)、[AtCoder](https://atcoder.jp/)(競技プログラミング)等の趣味が高じてフューチャーに入社しました。このような背景の人がフューチャーに入社後、何が不足していると感じ、どのようにそれを埋めていこうとしているのか。といった目線でお読みいただければ幸いです。

<img src="/images/20230222a/51yTAYkJ9XL._SY291_BO1,204,203,200_QL40_ML2_.jpg" alt="" width="207" height="293" loading="lazy">


## 本書を読んだ背景

入社後最初に配属されたプロジェクトで、とあるデータからの予測タスクを任されました。私も一応Kaggle等のコンペの経験者なので、予測タスクの土地勘はあります。まずはデータをLightGBMに入れてベースラインを作り、その後でクロスバリデーション(CV)の結果を見ながら特徴量を追加したり、ニューラルネットワーク系のモデルを中心に試す感じでしょうか。

#### 早速コンペの経験が活きそうです！

ですが、受け取ったデータはデータ数が300くらいしかありません。これはいわゆるスモールデータ。基礎的なデータ解析の力が重要になる分析です。

#### 私の経験だけでは足りません！

当然データサイエンスの基礎をきちんと学んだ上でコンペに参加している方であれば話は違うはずです。しかし私は、必要になった知識を都度学ぶスタイルで、データサイエンスの基礎を体系的に学んだ経験がありません。ですので、経験のある分野ではある程度のパフォーマンスを出せると思いますが、何か初歩的な内容で不足してる知識があるかもしれません。このままプロジェクトに入るのは不安です。

また、上司に聞いても、スモールデータの分析はよくあるとのことです。

#### 良い機会なので、ここでしっかり基礎を固めておきましょう。
というわけで、前置きが長くなりましたが、このような背景で本書を読んで学ぶことにした者による書評です。

## 本書の概要

ビッグデータを扱う際は、CVの結果を見て特徴量やモデルを選定する方法が有効ですが、スモールデータの解析では、誤差の影響が大きくなるためCV結果以外の重要度が高くなります。

本書はそのような背景を踏まえ、重回帰分析の重要性、理論的な背景、実際に適用する上での注意事項や対処方法の提案等に重点が置かれています。

また、通常のデータサイエンスの書籍は、複雑な式が多く理解するのは難しいですが、本書では、複雑な式をわかりやすいPythonコードに落とし込んだ説明が多く、競技プログラミングや競技データサイエンスの素養のある方には理解しやすくなっていると感じました。

## 目次

章立ては下記の通りです。

<details><summary>第１章　スモールデータとは</summary>
<dd>1.1  ビッグデータからスモールデータへ</dd>
<dd>1.2  スモールデータ解析の特徴</dd>
<dd>1.3  本書の構成</dd>
</details>
<details><summary>第２章　相関関係と主成分分析</summary>
<dd>2.1  データの前処理</dd>
<dd>2.2  共分散と相関関係</dd>
<dd>2.3  相関関係≠因果関係</dd>
<dd>2.4  多変数間の相関関係</dd>
<dd>2.5  主成分分析(PCA)とは</dd>
<dd>2.6  データの特徴</dd>
<dd>2.7  第1主成分の導出</dd>
<dd>2.8  第r主成分の導出</dd>
<dd>2.9  PCAの数値例</dd>
<dd>2.10 主成分数の決定</dd>
<dd>2.11 PCAの行列表現</dd>
<dd>2.12 PCAと特異値分解</dd>
</details>
<details><summary>第３章　回帰分析と最小二乗法</summary>
<dd>3.1  回帰分析とは</dd>
<dd>3.2  最小二乗法</dd>
<dd>3.3  回帰係数と相関係数</dd>
<dd>3.4  最小二乗法の幾何学的意味</dd>
<dd>3.5  ガウス-マルコフの定理</dd>
<dd>3.6  最尤法と最小二乗法</dd>
<dd>3.7  多重共線性の問題</dd>
<dd>3.8  サンプル数が入力変数の数よりも少ない場合</dd>
<dd>3.9  疑似逆行列を用いる方法</dd>
<dd>3.10 主成分回帰(PCR)</dd>
<dd>3.11 リッジ回帰</dd>
<dd>3.12 部分的最小二乗法(PLS)</dd>
<dd>3.13 PLS1モデルの導出</dd>
<dd>3.14 PLS1モデルのNIPALSアルゴリズム</dd>
<dd>3.15 重回帰モデルへの変換</dd>
<dd>3.16 出力変数が複数ある場合(PLS2)</dd>
<dd>3.17 PLSと固有値問題・特異値分解</dd>
<dd>3.18 ハイパーパラメータの調整</dd>
<dd>3.19 回帰モデルの性能評価</dd>
<dd>3.20 分光分析による物性推定</dd>
<dd>　　3.20.1 分光法</dd>
<dd>　　3.20.2 ディーゼル燃料の物性推定</dd>
</details>
<details><summary>第４章　線形回帰モデルにおける入力変数選択</summary>
<dd>4.1  オッカムの剃刀とモデルの複雑さ</dd>
<dd>4.2  赤池情報量規準(AIC)</dd>
<dd>4.3  ステップワイズ法</dd>
<dd>4.4  Lasso回帰</dd>
<dd>　　4.4.1 リッジ回帰に近似する方法</dd>
<dd>　　4.4.2 最小角回帰(LARS)</dd>
<dd>4.5  PLS向けの変数選択手法</dd>
<dd>4.6  相関関係に基づいた変数クラスタリングによる入力変数選択</dd>
<dd>　　4.6.1 クラスタリング</dd>
<dd>　　4.6.2 k-平均法</dd>
<dd>　　4.6.3 NCスペクトラルクラスタリング(NCSC)</dd>
<dd>　　4.6.4 NCSCの例題</dd>
<dd>　　4.6.5 NCSCを用いた入力変数選択(NCSC-VS)</dd>
<dd>4.7  NIRスペクトルの検量線入力波長選択</dd>
</details>
<details><summary>第５章　分類問題と不均衡データ問題</summary>
<dd>5.1  分類問題とは</dd>
<dd>5.2  線形判別分析</dd>
<dd>5.3  線形判別分析とレイリー商</dd>
<dd>5.4  カットオフの決定</dd>
<dd>5.5  線形判別分析と最小二乗法</dd>
<dd>5.6  分類モデルの性能評価</dd>
<dd>5.7  ROC曲線とAUC</dd>
<dd>5.8  線形判別分析における不均衡データ問題</dd>
<dd>5.9  データの不均衡度</dd>
<dd>5.10 サンプリング手法</dd>
<dd>5.11 アンダーサンプリング</dd>
<dd>　　5.11.1 サンプル選択型アンダーサンプリング</dd>
<dd>　　5.11.2 サンプル生成型アンダーサンプリング</dd>
<dd>　　5.11.3 オーバーサンプリング</dd>
<dd>　　5.11.4 アンダーサンプリングとオーバーサンプリングの組み合わせ</dd>
<dd>5.12 アンサンブル学習</dd>
<dd>5.13 判別木</dd>
<dd>5.14 バンキングとランダムフォレスト</dd>
<dd>5.15 ブースティング</dd>
<dd>　　5.15.1 AdaBoost</dd>
<dd>5.16 サンプリング手法とアンサンブル学習の組み合わせ</dd>
<dd>5.17 不均衡データにおける性能評価</dd>
<dd>5.18 ケーススタディ</dd>
<dd>　　5.18.1 データセットの準備</dd>
<dd>　　5.18.2 モデルの学習</dd>
<dd>　　5.18.3 モデル学習結果</dd>
</details>
<details><summary>第６章　異常検知問題</summary>
<dd>6.1  局所外れ値因子法(LOF)</dd>
<dd>　　6.1.1 局所密度</dd>
<dd>　　6.1.2 到達可能性距離</dd>
<dd>6.2  アイソレーションフォレスト</dd>
<dd>6.3  多変量統計的プロセス管理(MSPC)</dd>
<dd>　　6.3.1  USPCとMSPC</dd>
<dd>　　6.3.2  T<SUP>2</SUP>統計量とQ統計量</dd>
<dd>　　6.3.3  寄与プロットによる異常診断</dd>
<dd>6.4  オートエンコーダ(AE)</dd>
<dd>6.5  管理限界の調整</dd>
<dd>6.6  時系列データの取り扱い</dd>
<dd>6.7  砂山のパラドックス</dd>
<dd>6.8  Tennessee Eastman プロセスの異常検知</dd>
<dd>　　6.8.1  TEプロセス</dd>
<dd>　　6.8.2  データの前処理</dd>
<dd>6.9  モデルの学習と異常検知</dd>
<dd>6.10 異常検知結果</dd>
<dd>　　6.10.1 異常診断</dd>
</details>
<details><summary>第７章　データ収集や解析の心構え</summary>
<dd>7.1  機械学習の手順</dd>
<dd>7.2  そもそもデータを使って何をやりたいのか</dd>
<dd>7.3  PICO</dd>
<dd>7.4  データの文脈を理解する</dd>
<dd>7.5  現地現物と三現主義</dd>
<dd>7.6  現場とのコミュニケーション</dd>
<dd>7.7  解析データセット構築に責任を持つ</dd>
<dd>7.8  どうしてもうまくいかないときは</dd>
</details>
<details><summary>付録</summary>
<dd>A.1  標本分散と母分散</dd>
<dd>A.2  LARSアルゴリズム</dd>
<dd>A.3  Mcut法と固有値問題</dd>
<dd>A.4  主成分分析と自己符号化器の関係</dd>
</details>


## 本書の良かった(役に立った)点

### 2,3章
2,3章では、重回帰分析の理論的な背景,共分散の回避方法等について述べられています。

Kaggle等に参加する方であれば、それらがどのようなものか、「ある程度の知識」をお持ちの方が多いと思います。しかし、プロジェクトで行うデータ解析は、社内や、クライアント等とのチームで進めるものです。よって必要な知識、理解のレベルは、自分で使えれば良いレベルではなく、他者に説明できて、プロジェクトを進められるレベルです。

本章を通じ、重回帰分析の長所と短所、なぜ共分散を回避しなければならないのか、回避する選択肢として選べる方法等の理解を深めました。そして今も、「ある程度の知識」レベルから他者に説明しながらプロジェクトを進められるレベルを目指して学習しています。

### 4章

4章では特徴量の選択について述べられています。

予測に使用する特徴量は、ドメイン知識等から決定できれば良いですが、常にそれができるとは限りません。プロジェクト進行上本章の内容はまだ直接役立ってはいませんが、一般的に用いられる特徴量選択手法の中から目的に合った方法を選択・提案し、チームの納得を得て使用する特徴量を採択する場面が生じるはずです。本章により体系的な知識の備えができたことで、自信を持ってプロジェクトに携わることができています。

### 5章

5章は不均衡データへの対応について述べられています。

異常値検出等、分類タスクの中にはクラス毎のデータ数が著しく偏っているケースもあります。そのような場合に、どのようにサンプリングするか、結果を評価するか等が中心です。この辺りは、コンペの経験者であれば何度か痛い目に合って身につけた内容かと思います。ただ、体系的に学ぶことができましたので、今後このような場面でも、基本的な知識で不足しているものがないか不安を覚えることなくタスクに取り組むことができます。

## 本書では扱わない点
scikit-learn等のライブラリを使用した実用的なコードに関しては本書の対象外です。そちらが必要な場合は、他で学習する必要がありますので、ご注意ください。

## 最後に
データ解析の分野を１冊の本で理解できることは少ないと思いますが、競技データサイエンス、競技プログラミング出身の方等で、数式よりもPythonコードの方が理解が速い、という方の学習に役に立つ１冊だと感じました。

これからも新しい業務と出会えるたびに学び直しを行いますが、その際に使用した書籍を記事にしていきたいと思います。

