title: "NIPS2017 LT報告"
date: 2018/02/22 10:18:28
postid: ""
tag:
  - 機械学習
  - NIPS
  - LT
  - 論文紹介
category:
  - DataScience
author: 小池優希
featured: false
lede: "NIPS2017 LT報告"
---
# はじめに

みなさんこんにちは。
データサイエンスチームの小池です。[前回の記事](/articles/20170526/)を書いてから半年ぶりの登場となります。
データサイエンスチームでは定期的に勉強会を開催しているのですが、特別イベントとして有志でNIPS 2017 LT大会を開催しました。今回はLT大会の様子と発表された論文を紹介いたします。

# NIPSとは
ところでみなさんNIPSをご存知でしょうか。
[NIPS（Neural Information Processing Systems）](https://nips.cc/)は機械学習（AI）系のトップカンファレンスで、
今最も熱い学会です。最近のAIブームもあり、提出論文数は年々増え続け2017年には3,240本もの論文が提出されました。（論文は[こちら]( https://papers.nips.cc/book/advances-in-neural-information-processing-systems-30-2017 )から読むことができます。）

そんな中、データサイエンスチームは今年の新人を誘ってNIPS2017LT大会を実施しました。
（ちなみにNIPS2017のaccepted paperの紹介がメインですが、NIPS以外に読みたい論文があれば、その紹介もOKとしました）


# NIPS2017 LT大会の様子
LT大会はメンバーが多いため3回に分けて行われました。
数式ベースから紹介するものやデモを用いたもの、ITコンサルタントとしてそれを業務にどう活かしていくかという話題もあり、私個人にとっても非常に有益でした。


<img src="/images/20180222/photo_20180222_01.jpeg" loading="lazy">


大会中は熱い議論交わされも行われ 大いに盛り上がりました。


<img src="/images/20180222/photo_20180222_02.jpeg" loading="lazy">



# NIPS2017LT大会で紹介された論文の概要
ここからは今大会で発表された論文をいくつか紹介いたします。
なお論文のまとめには新人の田中さんに手伝っていただきました。

## NIPS 2017論文

- Learned in Translation: Contextualized Word Vectors(Bryan McCann et. al. NIPS2017)

NLPのタスクではword vectorが用いられますが、contextの表現能力が十分ではありません。そこでcontextualized word vector(CoVe)を提案しています。CoVeは機械翻訳で学習されたseq2seq LSTM encoderから得られます。実験の結果、様々なNLPタスクでCoVeを用いることで良い結果が得られました。なお、余談になりますが先日ELMoという新しいembedding法が提案されました。CoVeとの比較もされており、より精度が高いとされています。

<img src="/images/20180222/photo_20180222_03.png" loading="lazy">

</br>
</br>

- What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?(Alex Kendall et. al. NIPS 2017)


画像処理における不確実性には偶発的不確実性(Aleatoric uncertainty)と認知的不確実性(Epistemic uncertainty)の2種類があります。偶発的不確実性とは、訓練データが不足するために生じる不確かさで、認知的不確実性とは訓練データがどれだけ多くあっても十分に説明できない情報に対する不確かさです。従来はどちらか一方しか考慮できませんでしたが、本論文では偶発的不確実性と認知的不確実性の両方を考慮可能な Bayesian deep learning frameworkの提案をしています。Bayesian deep learningでは、事後分布を推定することができるため不確実性の度合いを認識できます。 偶発的不確実性と認知的不確実性を従来の手法にBayesian neural networksを加えることによって考慮できるようにしています。画像判別タスクにこのNNを用いた結果、従来の手法より精度が向上しました。

<img src="/images/20180222/photo_20180222_04.png" loading="lazy">
</br>

- Best of Both Worlds: Transferring Knowledge from　Discriminative Learning to a Generative Visual Dialog Model(Jiasen Lu et al. NIPS2017)

画像に対しての質問をすると、対話の中で質問に受け答えするようなモデルの提案を行っています。 従来手法は対話生成にRNNを用いている一方、本手法ではGANを使用していることが特徴となります。ただし、ここで用いているGANは一般的なGANとは異なっています。Discriminator は、会話のリストを受け取り、受け答えとして自然なものは高いスコアをつけるように学習します。一方Generatorは、自分の生成した会話をDiscriminator に高いスコアを付けてもらえるような会話を生成しようと試みます。本論文では従来手法よりも高い精度で対話の応答ができたという結果が示されています。


<img src="/images/20180222/photo_20180222_05.png" loading="lazy">


</br>

- Stabilizing Training of Generative Adversarial Networks through Regularization (Kevin Roth et al. NIPS2017)

GANの学習は設定パラメーターに対してセンシティブに過ぎることが多く、質が良いアウトプットを出すことは困難です。この課題を解決するためにDiscriminatorにノイズを入れる方法が知られています。本論文ではノイズ追加などを数式的に分析し、偽データに対するDiscriminatorの勾配を正規化するよう手法を提案しています。これは余談になるのですが、Githubに[コード](https://github.com/rothk/Stabilizing_GANs)も公開されていたため、モデルに実装してみたところ、確かにDiscriminatorとGeneratorの学習がうまい具合に進みました。GANに興味がある方はぜひトライしてみてください。




</br>



- Poincaré Embeddings for Learning Hierarchical Representations(Maximilian Nickel et al. NIPS2017)

一般的な機械学習における表現獲得にはユークリッド空間が利用されますが、本論文では表現獲得にPoincaré空間の利用を試みています。Poincaré空間は双曲空間の一種であり、距離の定義が式1で表される空間のことです。Poincaré空間を用いる利点として、ユークリッド空間と比較して、超球の外にいけばいくほど距離が密になるので効率良く空間を利用できることがあげられます。Poincaré空間にembeddingすることで、ユークリッド空間で200次元が必要だったタスクがたったの5次元で同精度を得ることができました。
<img src="/images/20180222/photo_20180222_06.png"  class="img-small-size" loading="lazy">

<img src="/images/20180222/photo_20180222_07.png" loading="lazy">



</br>

## その他論文

- A Comprehensive Survey on Cross-modal Retrieval(Kaiye Wang et al. IEEE2016)

画像から文字を検索したり、文字から動画を検索したりするcross modal検索の既存手法を整理した論文です。
cross modal検索の手法はいくつか提案されていますが、各手法の得手・不得手に加え、各特徴をまとめています。 例えば、画像および文書をベクトル化する手法には、Binaryにする手法と実数値を用いる手法がありますが、前者は検索が早い一方、後者は精度が良いという傾向が示されています。各手法に対し、オープンタスクでの精度の比較も行っています。
</br>

- Comicolorization: Semi-Automatic Manga Colorization(Chie Furusawa et al. SIGGRAPH Asia 2017)

白黒漫画１タイトル＋参照画像と呼ばれるキャラクターのカラー画像を入力とし、白黒漫画をディープラーニングで自動着色する論文です。
白黒写真を自動彩色するCNN（http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/data/colorization_sig2016.pdf）から以下の3点を変更することによって、キャラクターを分類した上で、キャラクター毎に鮮やかに自動着色しています。

- キャラクターを分類しやすくするため 、クラス分類を行うネットワークのラベルをキャラクターのラベルに変更
- 色彩特徴量の効果を促進するため、CNNでは使用されていなかったDiscriminatorを追加
- インタラクティブな彩色を可能にするため、学習時に参照画像内のキャラクターに使われている色の有無を示すベクトルを抽出し追加
<img src="/images/20180222/photo_20180222_08.png" loading="lazy">




# 終わりに
今回初の試みであるNIPS2017LT大会は、最新の機械学習の動向をメンバー間で共有することができました。
機械学習の最先端である手法を学び、それらを業務にどう活かしていくかという議論もでき非常に有益でした。
フューチャーアーキテクトのデータサイエンスチームでは、最先端の機械学習を用いて顧客の課題を解決できるエンジニアを募集しています。
興味がある方は[こちら](https://www.future.co.jp/recruit/)からエントリーをお願いします。より良い未来を一緒に作っていきましょう！

## 予告
次回はICLR2018のLT大会を行います。お楽しみに。


